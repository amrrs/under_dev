---
title: "Text Analysis with 1 Million News Headlines"
output: html_document
---

```{r setup, include=FALSE}
news <- read.csv('../input/million-headlines/abcnews-date-text.csv', header = T, stringsAsFactors = F)
knitr::opts_chunk$set(echo = TRUE)
```

## What is the purpose of this Kernel:

The primary aim of this Kernel is to introduce this simple-to-use but effective R package `udpipe` for Text Analysis. 

## About udpipe Package 

UDPipe - R package provides *language-agnostic* tokenization, tagging, lemmatization and dependency parsing of raw text, which is an essential part in natural language processing.


## Input Dataset 

This includes the entire corpus of articles published by the ABC website in the given time range. With a volume of 200 articles per day and a good focus on international news, we can be fairly certain that every event of significance has been captured here.

```{r}
library(dplyr)
library(ggplot2)
news %>% group_by(publish_date) %>% count() %>% arrange(desc(n))
```

Plotting to understand how the frequency of headlines is:

```{r}
news %>% group_by(publish_date) %>% count() %>% ggplot() + geom_line(aes(publish_date,n))
```

Before we move on to perform text analysis let's split year, month and date

```{r}
library(stringr)
news_more <- news %>% mutate(year = str_sub(publish_date,1,4),
                        month = str_sub(publish_date,5,6),
                        date = str_sub(publish_date,7,8))

```

Let us see the distribution of data based on year and month

```{r}
news_more %>% group_by(year) %>% count()  %>% ggplot() + geom_bar(aes(year,n), stat ='identity')

```



## Pre-trained Model

Udpipe Package provides pretrained language models for respective languages (not programming - but spoken) and we can download the required model using `udpipe_download_model()`


## Loading R package and Getting Language Model ready

```{r}
library(udpipe)
#model <- udpipe_download_model(language = "english")
udmodel_english <- udpipe_load_model(file = '../input/udpipe-english-model-pretrained/english-ud-2.0-170801.udpipe')

```

## Filtering data only for 2008

```{r}
news_more_2008 <- news_more %>% filter(year == 2008)

```


## Annotate Input Text Data for 2008 

This is the very first function that we'd use in `udpipe` to get started with our Text Analysis journey. `udpipe_annotate()` takes the language model and annoates the given text data

```{r}
x <- udpipe_annotate(udmodel_english, news_more_2008$headline_text)
```

## Universal POS

Plotting Part-of-speech tags from the given text

```{r}
library(lattice)
stats <- txt_freq(x$upos)
stats$key <- factor(stats$key, levels = rev(stats$key))
barchart(key ~ freq, data = stats, col = "cadetblue", 
         main = "UPOS (Universal Parts of Speech)\n frequency of occurrence", 
         xlab = "Freq")
```

## Most Occuring Nouns

Since we've got the text annotated with Part of Speech, let's understand the most common words of nouns.

```{r}
## NOUNS
stats <- subset(x, upos %in% c("NOUN")) 
stats <- txt_freq(stats$token)
stats$key <- factor(stats$key, levels = rev(stats$key))
barchart(key ~ freq, data = head(stats, 20), col = "cadetblue", 
         main = "Most occurring nouns", xlab = "Freq")
```

## Most Occuring Adjectives


It'd be very hard to find a news agency that doesn't like exaggerating and in English, you exaggerate your object with Adjective. So, let's explore the most occuring Adjectives

```{r}
## ADJECTIVES
stats <- subset(x, upos %in% c("ADJ")) 
stats <- txt_freq(stats$token)
stats$key <- factor(stats$key, levels = rev(stats$key))
barchart(key ~ freq, data = head(stats, 20), col = "cadetblue", 
         main = "Most occurring adjectives", xlab = "Freq")
```


